<!DOCTYPE html><html lang="en" class="scroll-smooth" data-astro-transition-scope="astro-smooz4hq-1"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.png"><link rel="canonical" href="https://www.vtsakalos.com/posts/feature-engineering-f-machine-learning/"><meta name="generator" content="Astro v4.4.0"><!-- General Meta Tags --><title>Vasileios Tsakalos | Feature engineering for Machine Learning</title><meta name="title" content="Vasileios Tsakalos | Feature engineering for Machine Learning"><meta name="description" content="Dive into the art of 'Feature Engineering for Machine Learning' with this comprehensive article, where we delve into the crucial process of crafting effective features to enhance model performance. Through insightful explanations and practical Python implementations, learn essential techniques to preprocess and engineer features, empowering your machine learning models with the ability to extract meaningful insights from data."><meta name="author" content="Vasileios Tsakalos"><link rel="sitemap" href="/sitemap-index.xml"><!-- Open Graph / Facebook --><meta property="og:title" content="Vasileios Tsakalos | Feature engineering for Machine Learning"><meta property="og:description" content="Dive into the art of 'Feature Engineering for Machine Learning' with this comprehensive article, where we delve into the crucial process of crafting effective features to enhance model performance. Through insightful explanations and practical Python implementations, learn essential techniques to preprocess and engineer features, empowering your machine learning models with the ability to extract meaningful insights from data."><meta property="og:url" content="https://www.vtsakalos.com/posts/feature-engineering-f-machine-learning/"><meta property="og:image" content="https://www.vtsakalos.com/posts/feature-engineering-for-machine-learning.png"><!-- Article Published/Modified time --><meta property="article:published_time" content="2023-08-15T08:58:32.283Z"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://www.vtsakalos.com/posts/feature-engineering-f-machine-learning/"><meta property="twitter:title" content="Vasileios Tsakalos | Feature engineering for Machine Learning"><meta property="twitter:description" content="Dive into the art of 'Feature Engineering for Machine Learning' with this comprehensive article, where we delve into the crucial process of crafting effective features to enhance model performance. Through insightful explanations and practical Python implementations, learn essential techniques to preprocess and engineer features, empowering your machine learning models with the ability to extract meaningful insights from data."><meta property="twitter:image" content="https://www.vtsakalos.com/posts/feature-engineering-for-machine-learning.png"><!-- Google Font --><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,400;0,500;0,600;0,700;1,400;1,600&display=swap" rel="stylesheet"><meta name="theme-color" content=""><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script src="/toggle-theme.js"></script><link rel="stylesheet" href="/_astro/index.CiARLz32.css" />
<style>.pagination-wrapper:where(.astro-d776pwuy){margin-bottom:1rem;margin-top:auto;display:flex;-webkit-user-select:none;-moz-user-select:none;user-select:none;justify-content:center}.disabled:where(.astro-d776pwuy){pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none;opacity:.5}.disabled:where(.astro-d776pwuy):hover{--tw-text-opacity: 1;color:rgba(var(--color-text-base),var(--tw-text-opacity))}.group:where(.astro-d776pwuy):hover .disabled:where(.astro-d776pwuy){fill:rgb(var(--color-text-base))}.group:where(.astro-d776pwuy):hover .disabled-svg:where(.astro-d776pwuy){fill:rgb(var(--color-text-base))!important}
a:where(.astro-blwjyjpt){position:relative;text-decoration-line:underline;text-decoration-style:dashed}a:where(.astro-blwjyjpt):hover{top:-.125rem;--tw-text-opacity: 1;color:rgba(var(--color-accent),var(--tw-text-opacity))}a:where(.astro-blwjyjpt):focus-visible{padding:.25rem}a:where(.astro-blwjyjpt) svg:where(.astro-blwjyjpt){margin-right:-1.25rem;height:1.5rem;width:1.5rem;--tw-scale-x: .95;--tw-scale-y: .95;transform:translate(var(--tw-translate-x),var(--tw-translate-y)) rotate(var(--tw-rotate)) skew(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));--tw-text-opacity: 1;color:rgba(var(--color-text-base),var(--tw-text-opacity));opacity:.8}.group:where(.astro-blwjyjpt):hover a:where(.astro-blwjyjpt) svg:where(.astro-blwjyjpt){fill:rgb(var(--color-accent))}
main:where(.astro-rynkmgph){margin-left:auto;margin-right:auto;width:100%;max-width:64rem;padding-left:1rem;padding-right:1rem;padding-bottom:3rem}.post-title:where(.astro-rynkmgph){font-size:1.5rem;line-height:2rem;font-weight:600;--tw-text-opacity: 1;color:rgba(var(--color-accent),var(--tw-text-opacity))}
</style><script type="module" src="/_astro/hoisted.B2MTPbHz.js"></script><style>[data-astro-transition-scope="astro-smooz4hq-1"] { view-transition-name: astro-smooz4hq-1; }@layer astro { ::view-transition-old(astro-smooz4hq-1) { animation: none; opacity: 0; mix-blend-mode: normal; }::view-transition-new(astro-smooz4hq-1) { animation: none; mix-blend-mode: normal; } }[data-astro-transition-fallback="old"] [data-astro-transition-scope="astro-smooz4hq-1"],
			[data-astro-transition-fallback="old"][data-astro-transition-scope="astro-smooz4hq-1"] { animation: none; mix-blend-mode: normal; }[data-astro-transition-fallback="new"] [data-astro-transition-scope="astro-smooz4hq-1"],
			[data-astro-transition-fallback="new"][data-astro-transition-scope="astro-smooz4hq-1"] { animation: none; mix-blend-mode: normal; }</style></head> <body>  <header class="astro-3ef6ksr2"> <a id="skip-to-content" href="#main-content" class="astro-3ef6ksr2">Skip to content</a> <div class="nav-container astro-3ef6ksr2"> <div class="top-nav-wrap astro-3ef6ksr2"> <a href="/" class="logo whitespace-nowrap astro-3ef6ksr2"> Vasileios Tsakalos </a> <nav id="nav-menu" class="astro-3ef6ksr2"> <button class="hamburger-menu focus-outline astro-3ef6ksr2" aria-label="Open Menu" aria-expanded="false" aria-controls="menu-items"> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="menu-icon astro-3ef6ksr2"> <line x1="7" y1="12" x2="21" y2="12" class="line astro-3ef6ksr2"></line> <line x1="3" y1="6" x2="21" y2="6" class="line astro-3ef6ksr2"></line> <line x1="12" y1="18" x2="21" y2="18" class="line astro-3ef6ksr2"></line> <line x1="18" y1="6" x2="6" y2="18" class="close astro-3ef6ksr2"></line> <line x1="6" y1="6" x2="18" y2="18" class="close astro-3ef6ksr2"></line> </svg> </button> <ul id="menu-items" class="display-none sm:flex astro-3ef6ksr2"> <li class="astro-3ef6ksr2"> <a href="/posts/" class="active astro-3ef6ksr2">
Posts
</a> </li> <li class="astro-3ef6ksr2"> <a href="/tags/" class=" astro-3ef6ksr2">
Tags
</a> </li> <li class="astro-3ef6ksr2"> <a href="/projects/" class=" astro-3ef6ksr2">
Projects
</a> </li> <li class="astro-3ef6ksr2"> <a href="/services/" class=" astro-3ef6ksr2">
Services
</a> </li> <li class="astro-3ef6ksr2"> <a href="/about/" class=" astro-3ef6ksr2">
About
</a> </li> <li class="astro-3ef6ksr2"> <a href="/search/" class="group hover:text-skin-accent focus-outline p-3 sm:p-1  flex astro-3ef6ksr2" aria-label="Search" title="Search" target="_self"> <svg xmlns="http://www.w3.org/2000/svg" class="scale-125 sm:scale-100 astro-3ef6ksr2"><path d="M19.023 16.977a35.13 35.13 0 0 1-1.367-1.384c-.372-.378-.596-.653-.596-.653l-2.8-1.337A6.962 6.962 0 0 0 16 9c0-3.859-3.14-7-7-7S2 5.141 2 9s3.14 7 7 7c1.763 0 3.37-.66 4.603-1.739l1.337 2.8s.275.224.653.596c.387.363.896.854 1.384 1.367l1.358 1.392.604.646 2.121-2.121-.646-.604c-.379-.372-.885-.866-1.391-1.36zM9 14c-2.757 0-5-2.243-5-5s2.243-5 5-5 5 2.243 5 5-2.243 5-5 5z" class="astro-3ef6ksr2"></path> </svg> <span class="sr-only astro-3ef6ksr2">Search</span> </a> </li> <li class="astro-3ef6ksr2"> <button id="theme-btn" class="focus-outline astro-3ef6ksr2" title="Toggles light & dark" aria-label="auto" aria-live="polite"> <svg xmlns="http://www.w3.org/2000/svg" id="moon-svg" class="astro-3ef6ksr2"> <path d="M20.742 13.045a8.088 8.088 0 0 1-2.077.271c-2.135 0-4.14-.83-5.646-2.336a8.025 8.025 0 0 1-2.064-7.723A1 1 0 0 0 9.73 2.034a10.014 10.014 0 0 0-4.489 2.582c-3.898 3.898-3.898 10.243 0 14.143a9.937 9.937 0 0 0 7.072 2.93 9.93 9.93 0 0 0 7.07-2.929 10.007 10.007 0 0 0 2.583-4.491 1.001 1.001 0 0 0-1.224-1.224zm-2.772 4.301a7.947 7.947 0 0 1-5.656 2.343 7.953 7.953 0 0 1-5.658-2.344c-3.118-3.119-3.118-8.195 0-11.314a7.923 7.923 0 0 1 2.06-1.483 10.027 10.027 0 0 0 2.89 7.848 9.972 9.972 0 0 0 7.848 2.891 8.036 8.036 0 0 1-1.484 2.059z" class="astro-3ef6ksr2"></path> </svg> <svg xmlns="http://www.w3.org/2000/svg" id="sun-svg" class="astro-3ef6ksr2"> <path d="M6.993 12c0 2.761 2.246 5.007 5.007 5.007s5.007-2.246 5.007-5.007S14.761 6.993 12 6.993 6.993 9.239 6.993 12zM12 8.993c1.658 0 3.007 1.349 3.007 3.007S13.658 15.007 12 15.007 8.993 13.658 8.993 12 10.342 8.993 12 8.993zM10.998 19h2v3h-2zm0-17h2v3h-2zm-9 9h3v2h-3zm17 0h3v2h-3zM4.219 18.363l2.12-2.122 1.415 1.414-2.12 2.122zM16.24 6.344l2.122-2.122 1.414 1.414-2.122 2.122zM6.342 7.759 4.22 5.637l1.415-1.414 2.12 2.122zm13.434 10.605-1.414 1.414-2.122-2.122 1.414-1.414z" class="astro-3ef6ksr2"></path> </svg> </button> </li> </ul> </nav> </div> </div> <div class="mx-auto px-4"> <hr class="border-skin-line" aria-hidden="true"> </div> </header>   <div class="mx-auto flex w-full max-w-5xl justify-start px-2 astro-rynkmgph"> <button class="focus-outline mb-2 mt-8 flex hover:opacity-75 astro-rynkmgph" onclick="(() => (history.length === 1) ? window.location = '/' : history.back())()"> <svg xmlns="http://www.w3.org/2000/svg" class="astro-rynkmgph"><path d="M13.293 6.293 7.586 12l5.707 5.707 1.414-1.414L10.414 12l4.293-4.293z" class="astro-rynkmgph"></path> </svg><span class="astro-rynkmgph">Go back</span> </button> </div> <main id="main-content" class="astro-rynkmgph"> <h1 class="post-title astro-rynkmgph">Feature engineering for Machine Learning</h1> <div class="flex items-center space-x-2 opacity-80 my-2 astro-rynkmgph"><svg xmlns="http://www.w3.org/2000/svg" class="scale-100 inline-block h-6 w-6 min-w-[1.375rem] fill-skin-base" aria-hidden="true"><path d="M7 11h2v2H7zm0 4h2v2H7zm4-4h2v2h-2zm0 4h2v2h-2zm4-4h2v2h-2zm0 4h2v2h-2z"></path><path d="M5 22h14c1.103 0 2-.897 2-2V6c0-1.103-.897-2-2-2h-2V2h-2v2H9V2H7v2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2zM19 8l.001 12H5V8h14z"></path></svg><span class="sr-only">Published:</span><span class="italic text-base"><time dateTime="2023-08-15T08:58:32.283Z">Aug 15, 2023</time><span aria-hidden="true"> | </span><span class="sr-only"> at </span><span class="text-nowrap">04:58 PM</span></span></div> <article id="article" role="article" class="prose max-w-full mt-4 astro-rynkmgph"> <p>Feature engineering, plays a crucial role in machine learning algorithms. Feature engineering methods can be applied to numerical, categorical and textual data. Some of the key benefits of feature engineering are:</p>
<ol>
<li>
<p>Improved <a href="https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide#:~:text=Performance%20metrics%20are%20a%20part,a%20metric%20to%20judge%20performance">performance</a>: by feature engineering, you can help the ML algorithm detect patterns easier. For example, in a model where you try to predict the prison sentence a guilty person given the committed crime - a good feature could be identifying adults (age > 17) since juveniles receive reduced sentences for the same crime;</p>
</li>
<li>
<p>Increase <a href="https://www.interpretable.ai/interpretability/what/#:~:text=What%20does%20it%20mean%20to,comprehend%20and%20trust%20the%20model">Model Interpretability</a>: by transforming the features or creating new features you can capture meaningful patterns and relationships in the data. This can support the understanding of the underlying data;</p>
</li>
<li>
<p>Handling categorical and textual data: majority of popular machine learning algorithms require numerical data, while in real life most features are categorical or textual data. Feature engineering can enables us to use such data;</p>
</li>
<li>
<p>Handling <a href="https://en.wikipedia.org/wiki/Nonlinear_system#:~:text=In%20mathematics%20and%20science%2C%20a,the%20change%20of%20the%20input.">non-linear</a> relationships: feature engineering can help capture non-linear relationships.</p>
</li>
</ol>
<h1 id="numerical-features">Numerical features</h1>
<h2 id="discretization--binning">Discretization / Binning</h2>
<p>Discretization is the method of dividing continuous numerical variables into discrete intervals or bins. This method is great to deal with non-linear relationships or <a href="https://en.wikipedia.org/wiki/Outlier">outliers</a>. An example of discretization is identifying a person’s generation based on their age.</p>
<p><img  src="/_astro/binning.D62nf9cu_ZhHXT8.webp" alt="IR systems" width="988" height="390" loading="lazy" decoding="async"></p>
<h2 id="scaling-and-normalization">Scaling and Normalization</h2>
<p>Scaling and normalization methods ensure that numerical features are on a similar scale. This is extremely important when you are using one of the following algorithms:</p>
<ul>
<li>
<p><strong>Gradient-descent based models</strong>, because the optimization algorithm converges faster and prevents certain features to dominate due to differences to their scales</p>
</li>
<li>
<p><strong>Distance based models</strong>, because they are sensitive to scales. Scaling ensures each feature contributes proportionally and features with larger scales wouldn’t dominate.</p>
</li>
<li>
<p><strong><a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">Regularized models</a></strong>, scaling makes sure all the features are regularized equally.</p>
</li>
<li>
<p><strong><a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a></strong>, they are sensitive to feature scaling because they aim to identify the hyperplane which separates the classes and larger scale may dominate.</p>
</li>
<li>
<p><strong><a href="https://builtin.com/data-science/step-step-explanation-principal-component-analysis">Principal Component Analysis</a></strong> (PCA), scaling features is important because PCA aims to find the directions of maximum variance so having different scales would lead to have different variance even though proportionaly they are not.</p>
</li>
</ul>
<p><a href="https://www.analyticsvidhya.com/blog/2021/04/distinguish-between-tree-based-machine-learning-algorithms/">Tree-based</a> models are invariant to feature scaling.</p>
<p>Common methods for feature  scaling are:</p>
<ul>
<li><strong>Standardization (Z-Score normalization)</strong>: Standardization is great to use when your data have outliers (you get a better quantification and detection of outliers). Z-score normalization is calculated by subtracting the mean from each data point and dividing by the standard deviation. It centers the data around zero and scales it based on standard deviation.</li>
</ul>
<p><img  src="/_astro/normalize.CBWwT-NG_wAJQ3.webp" alt="z_score" width="83" height="33" loading="lazy" decoding="async">
<img  src="/_astro/z_scored.BhLTFuHD_11ETD.webp" alt="z_scored" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Min-max scaling</strong>: Min-max scaling transforms linearly the data to a range [0, 1], it is great to use if you want to keep the data distribution but be careful because it is sensitive to outliers (outliers should be treated before applying min-max scaling). Min-max scaling is calculated by subtracting every data point (x) with the minimum value to shift the minimum value to 0, then divide the result by the range to scale the data within the desired range.</li>
</ul>
<p><img  src="/_astro/min_max.bAcrZCzz_1LEgp7.webp" alt="min_max" width="252" height="62" loading="lazy" decoding="async">
<img  src="/_astro/min_maxed.D2Eff-2j_Z10OgEL.webp" alt="min_maxed" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Max absolute scaling</strong>: similar to min-max scaling transforms linearly the data to a range of [-1, 1]. Max absolute scaling is calculated by dividing every data point (x) with the maximum absolute value.</li>
</ul>
<p><img  src="/_astro/ma.DqKUSCnn_Z13Knke.webp" alt="ma" width="157" height="53" loading="lazy" decoding="async">
<img  src="/_astro/maed.DxanPTbM_ZTcnEH.webp" alt="maed" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Robust scaling</strong>: it is a good transformation method to deal with outliers. It subtracts every every data point with the <a href="https://en.wikipedia.org/wiki/Median">median</a> and divide it by the <a href="https://en.wikipedia.org/wiki/Interquartile_range">interquartile range</a>.</li>
</ul>
<p><img  src="/_astro/iqr.D2LbSFbO_Zm0liy.webp" alt="iqr" width="185" height="59" loading="lazy" decoding="async">
<img  src="/_astro/iqred.CN4Rdnp0_1O9XEt.webp" alt="iqred" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li>
<p><strong>Power Transformation</strong>: it is a family of transformations aim to normalize skewed data, handle heteroscedasticity, reduce outlier influence, linearize non-linear relationships. Examples of power transformations are:</p>
<ul>
<li><strong>Log transformation</strong>: it is useful when data have outliers or when data have a right-skewed distribution, like the distribution at the left plot below.</li>
</ul>
<p><img  src="/_astro/log.DgMnOBGC_cVtD2.webp" alt="iqr" width="103" height="25" loading="lazy" decoding="async"></p>
<p><img  src="/_astro/loged.BcAOm_Eh_Z1vDIwq.webp" alt="iqred" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Square Root Transformation</strong>: can amplify smaller values making them more distinguishable, useful when data is left-skewed</li>
</ul>
<p><img  src="/_astro/log.DgMnOBGC_cVtD2.webp" alt="iqr" width="103" height="25" loading="lazy" decoding="async"></p>
<p><img  src="/_astro/loged.BcAOm_Eh_Z1vDIwq.webp" alt="iqred" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li>
<p><strong>Box-Cox transformation</strong>: good for normalizing data, lamda parameter needs to fine-tuned depending on the data
<img  src="/_astro/box_cox.BjO_tN7R_Z2w1hIt.webp" alt="iqr" width="988" height="390" loading="lazy" decoding="async"></p>
</li>
<li>
<p><strong>Yeo-Johnson Transformation</strong>: it is an extension of Box-Cox transformation that can handle negative values too</p>
</li>
</ul>
<p><img  src="/_astro/loged.BcAOm_Eh_Z1vDIwq.webp" alt="iqred" width="988" height="390" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Binary Scaling</strong>: Also known as binarization, this technique converts numerical features into binary values based on a given threshold. At the example below we set the threshold to 18, it would be the processing we would have done to create a feature “is_adult” if we have the age of people.</li>
</ul>
<p><img  src="/_astro/binary.Bu7BR1-Y_K5609.webp" alt="iqred" width="988" height="390" loading="lazy" decoding="async"></p>
</li>
</ul>
<p>Feature scaling is a step that can greatly improve the performance of machine leaning models. However, it is important to note that not all machine learning models require feature scaling (like tree-based). It is important to scale the numerical features in a similar range, so that features with different ranges don’t dominate the decision making just by their scale.</p>
<h1 id="feature-encoding">Feature encoding</h1>
<p>Feature encoding is the process of transforming categorical or textual data to numerical representations so that they can be utilized by machine learning algorithms. We will go through the most common feature encoding methodologies.</p>
<h2 id="categorical-data">Categorical data</h2>
<ul>
<li><strong>One-hot encoding</strong>: each category in the categorical feature is transformed into a binary vector. It is the simplest feature encoding methodology but the representation can be very sparse and cause <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a> issue if the categorical feature has too many categories.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/onehot.webp" alt="iqred" width="300">
</div>
<ul>
<li><strong>Label encoding</strong>: each category is mapped to an integer. This method is very useful if order matters, but it can cause problems if the order is not right since it would require a bit of more data to identify non-linear patterns.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/label.webp" alt="iqred" width="300">
</div>
<ul>
<li><strong>Ordinal encoding</strong>: similar to label encoding, but in this transformation you need to set a priori which is the right order. For example you can use it to represent education level.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/ordinal.webp" alt="iqred" width="300">
</div>
<ul>
<li><strong>Count Encoding</strong>: it replaces the category with the number of occurrences of the category in the dataset. This encoding captures the frequency of the categories and can be used for features with high-cardinality. It is important to note that this encoding methodology can introduce many errors if it is applied blindly. Look at the example below, it treats “Category” “A” and “B” the same due to their frequency.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/count.webp" alt="iqred" width="300">
</div>
<ul>
<li><strong>Hashing Encoding</strong>: applied a <a href="https://en.wikipedia.org/wiki/Hash_function">hash function</a> to the categorical feature(s) and transform the categories into a number or bins, something interesting about this method is that it can be applied in multiple features at a time. It is a great method to reduce the dimensionality when you try to encode a feature with high-cardinality. The example below it shows how hash encoding would map two categorical variables into 5 binary features.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/hash.webp" alt="iqred" width="400">
</div>
<ul>
<li><strong>Target Encoding</strong>: It replaces the category with the average target value of the corresponding category. This encoding method can be misleading if the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets">training set</a> is not very representative of the serve set.</li>
</ul>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/target.webp" alt="iqred" width="400">
</div>
<h2 id="textual-data">Textual data</h2>
<p>There are multiple  methods to transform text data into numerical representation. We will go from the simplest to the most complex methods. It is important to note that we don’t go through all the methods, because this is an active area of research and there is tons of methods that someone could use.</p>
<ul>
<li><strong>Bag-of-words (BOW)</strong>: BOW represents every document as a vector where the elements represent the unique words of the <a href="https://www.merriam-webster.com/dictionary/corpus#:~:text=%3A%20the%20body%20of%20a%20human,distinct%20from%20income%20or%20interest">corpus</a>. The values of the vector element reflect the frequency of the words found in the given document.</li>
</ul>
<p><img  src="/_astro/bow.CVmS892L_1uVMxY.webp" alt="iqred" width="1103" height="162" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Term Frequency-Inverse Document Frequency (TF-IDF)</strong>: it calculates the importance of every word in a given document within a corpus. It considers both the word (term) frequency (TF) and the scarcity of the word across the corpus (IDF).</li>
</ul>
<p><img  src="/_astro/tfidf.9Rf6PZqy_ZQjfLw.webp" alt="iqred" width="1480" height="160" loading="lazy" decoding="async"></p>
<ul>
<li><strong>N-gram representation</strong>: N-grams representation measures the co-occurrence of words or characters in a text. N-gram is a sequence of words or characters and it is used to capture the context of the words or characters in the text. In the example below we will illustrate how an n-gram representation can look like for n=2 and n=3.</li>
</ul>
<p><img  src="/_astro/n_gram.eB4bKk6y_Zmmeuz.webp" alt="iqred" width="1480" height="168" loading="lazy" decoding="async"></p>
<ul>
<li><strong>Word Embeddings</strong>: they represent words as a dense vector in a continuous vector space. An extension to word embeddings can be <a href="https://en.wikipedia.org/wiki/Sentence_embedding#:~:text=Sentence%20embedding%20is%20the%20collective,to%20vectors%20of%20real%20numbers">sentence embeddings</a> and <a href="https://arxiv.org/pdf/1707.02377.pdf">document embeddings</a>. Text embeddings are the most advanced method (so far) for numerically representing text. They are great to represent the semantics of words, which means that similar words should be nearby in the vector space. A well-trained word embedding model should map words to vector space the following way:</li>
</ul>
<p><img  src="/_astro/we.Bk0dWh1J_41XGD.webp" alt="iqred" width="1076" height="410" loading="lazy" decoding="async"></p>
<p>If you are interested in investigating text representation further, you could examine character-level representation (where you encode the characters as one-hot encoded) and Subword-level representation.</p>
<h1 id="python-implementation">Python implementation</h1>
<p>In this section we will go through a practical example illustrating how feature transformations can be applied and how can they impact the performance of our model. We will use the data trying to identify credit card fraud and can be downloaded from <a href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download">here</a>.</p>
<p>We will start by importing the required modules:</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> pandas </span><span style="color:#C678DD">as</span><span style="color:#ABB2BF"> pd</span></span>
<span class="line"><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> scipy </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> stats</span></span>
<span class="line"><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> sklearn.model_selection </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> train_test_split</span></span>
<span class="line"><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> sklearn.metrics </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> f1_score, precision_score, recall_score</span></span>
<span class="line"><span style="color:#C678DD">from</span><span style="color:#ABB2BF"> sklearn.linear_model </span><span style="color:#C678DD">import</span><span style="color:#ABB2BF"> LogisticRegression</span></span></code></pre>
<p>The next step is to download the data and keep the features we think are useful:</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic"># Load the dataset</span></span>
<span class="line"><span style="color:#ABB2BF">url </span><span style="color:#56B6C2">=</span><span style="color:#98C379"> "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"</span></span>
<span class="line"><span style="color:#ABB2BF">column_names </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> [</span><span style="color:#98C379">"age"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"workclass"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"education"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"sex"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"race"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"occupation"</span><span style="color:#ABB2BF">,</span><span style="color:#98C379">"hours-per-week"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"income"</span><span style="color:#ABB2BF">]</span></span>
<span class="line"><span style="color:#ABB2BF">data </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">read_csv</span><span style="color:#ABB2BF">(url, </span><span style="color:#E06C75;font-style:italic">header</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">None</span><span style="color:#ABB2BF">, </span><span style="color:#E06C75;font-style:italic">names</span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF">column_names)</span></span>
<span class="line"><span style="color:#ABB2BF">data </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> data[column_names]</span></span></code></pre>
<p>Let’s write some functions to help us evaluate the transformations faster:</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#C678DD">def</span><span style="color:#61AFEF"> set_train_test</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">data</span><span style="color:#ABB2BF">):</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Split the dataset into features and target variable</span></span>
<span class="line"><span style="color:#ABB2BF">    X </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> data.</span><span style="color:#61AFEF">drop</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">'income'</span><span style="color:#ABB2BF">, </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">)  </span><span style="color:#7F848E;font-style:italic"># Features</span></span>
<span class="line"><span style="color:#ABB2BF">    y </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> data[</span><span style="color:#98C379">'income'</span><span style="color:#ABB2BF">]  </span><span style="color:#7F848E;font-style:italic"># Target variable</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Split the dataset into training and testing subsets</span></span>
<span class="line"><span style="color:#C678DD">    return</span><span style="color:#61AFEF"> train_test_split</span><span style="color:#ABB2BF">(X, y, </span><span style="color:#E06C75;font-style:italic">test_size</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">0.2</span><span style="color:#ABB2BF">, </span><span style="color:#E06C75;font-style:italic">random_state</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">42</span><span style="color:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD">def</span><span style="color:#61AFEF"> evaluate_solution</span><span style="color:#ABB2BF">(</span><span style="color:#D19A66;font-style:italic">data</span><span style="color:#ABB2BF">):</span></span>
<span class="line"><span style="color:#ABB2BF">    </span></span>
<span class="line"><span style="color:#ABB2BF">    train_x, test_x, train_y, test_y </span><span style="color:#56B6C2">=</span><span style="color:#61AFEF"> set_train_test</span><span style="color:#ABB2BF">(data)</span></span>
<span class="line"><span style="color:#ABB2BF">    </span></span>
<span class="line"><span style="color:#ABB2BF">    model </span><span style="color:#56B6C2">=</span><span style="color:#61AFEF"> LogisticRegression</span><span style="color:#ABB2BF">()</span></span>
<span class="line"><span style="color:#ABB2BF">    model.</span><span style="color:#61AFEF">fit</span><span style="color:#ABB2BF">(train_x, train_y)</span></span>
<span class="line"><span style="color:#ABB2BF">    probs </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> model.</span><span style="color:#61AFEF">predict_proba</span><span style="color:#ABB2BF">(test_x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Predict on the test set</span></span>
<span class="line"><span style="color:#ABB2BF">    custom_threshold </span><span style="color:#56B6C2">=</span><span style="color:#D19A66"> 0.3</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Adjust the predicted labels based on the threshold</span></span>
<span class="line"><span style="color:#ABB2BF">    y_pred </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> (probs[:, </span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">] </span><span style="color:#56B6C2">>=</span><span style="color:#ABB2BF"> custom_threshold).</span><span style="color:#61AFEF">astype</span><span style="color:#ABB2BF">(</span><span style="color:#56B6C2">int</span><span style="color:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Calculate evaluation metrics</span></span>
<span class="line"><span style="color:#ABB2BF">    f1 </span><span style="color:#56B6C2">=</span><span style="color:#61AFEF"> f1_score</span><span style="color:#ABB2BF">(test_y, y_pred)</span></span>
<span class="line"><span style="color:#ABB2BF">    precision </span><span style="color:#56B6C2">=</span><span style="color:#61AFEF"> precision_score</span><span style="color:#ABB2BF">(test_y, y_pred)</span></span>
<span class="line"><span style="color:#ABB2BF">    recall </span><span style="color:#56B6C2">=</span><span style="color:#61AFEF"> recall_score</span><span style="color:#ABB2BF">(test_y, y_pred)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#7F848E;font-style:italic">    # Print the evaluation metrics</span></span>
<span class="line"><span style="color:#56B6C2">    print</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">"F1 score:"</span><span style="color:#ABB2BF">, f1)</span></span>
<span class="line"><span style="color:#56B6C2">    print</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">"Precision:"</span><span style="color:#ABB2BF">, precision)</span></span>
<span class="line"><span style="color:#56B6C2">    print</span><span style="color:#ABB2BF">(</span><span style="color:#98C379">"Recall:"</span><span style="color:#ABB2BF">, recall)</span></span></code></pre>
<p>Having the data loaded, let’s have a high-level look of them to see what transformations can we apply.</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF">data.</span><span style="color:#61AFEF">info</span><span style="color:#ABB2BF">()</span></span></code></pre>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/info.webp" alt="iqred" width="400">
</div>
<p>We can see we have only two numeric variables and the rest are categorical.</p>
<p>For the first experiment we will transform the categorical variables using one-hot encoding to form a baseline solution.</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF">one_hot </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> [</span><span style="color:#98C379">"workclass"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"education"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"race"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"occupation"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"sex"</span><span style="color:#ABB2BF">]</span></span>
<span class="line"><span style="color:#7F848E;font-style:italic"># apply one-hot encoding in categorical variables</span></span>
<span class="line"><span style="color:#ABB2BF">one_hot_data </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">get_dummies</span><span style="color:#ABB2BF">(data[one_hot], </span><span style="color:#E06C75;font-style:italic">prefix</span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF">one_hot)</span></span>
<span class="line"><span style="color:#ABB2BF">encoded_data </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">concat</span><span style="color:#ABB2BF">([data, one_hot_data], </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">).</span><span style="color:#61AFEF">drop</span><span style="color:#ABB2BF">(one_hot, </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">)</span></span>
<span class="line"><span style="color:#61AFEF">evaluate_solution</span><span style="color:#ABB2BF">(encoded_data)</span></span></code></pre>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/onehot_metric.webp" alt="iqred" width="300">
</div>
<p>Let’s conduct a transformation to the numeric variables and see if we can achieve better results.</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#ABB2BF">scale_negative </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> [</span><span style="color:#98C379">"age"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"hours-per-week"</span><span style="color:#ABB2BF">]</span></span>
<span class="line"><span style="color:#C678DD">for</span><span style="color:#ABB2BF"> s </span><span style="color:#C678DD">in</span><span style="color:#ABB2BF"> scale_negative:</span></span>
<span class="line"><span style="color:#ABB2BF">    scaled_data, _ </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> stats.</span><span style="color:#61AFEF">yeojohnson</span><span style="color:#ABB2BF">(data[s].values)</span></span>
<span class="line"><span style="color:#ABB2BF">    encoded_data[s] </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">Series</span><span style="color:#ABB2BF">(scaled_data.</span><span style="color:#61AFEF">flatten</span><span style="color:#ABB2BF">())</span></span>
<span class="line"><span style="color:#ABB2BF">    </span></span>
<span class="line"><span style="color:#61AFEF">evaluate_solution</span><span style="color:#ABB2BF">(encoded_data)</span></span></code></pre>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/enc_metrics.webp" alt="iqred" width="300">
</div>
<p>It turns out there are some benefits from scaling our data, it turns out Recall is getting a slight improvement.</p>
<p>Finally, let’s conduct another transformation to the categorical data and let’s encode one of the features as ordinal.</p>
<pre class="astro-code one-dark-pro" style="background-color:#282c34;color:#abb2bf; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0"><code><span class="line"><span style="color:#7F848E;font-style:italic"># ordinal encoding</span></span>
<span class="line"><span style="color:#ABB2BF">mapping_encoding </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> {</span><span style="color:#98C379">' Preschool'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">0</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 1st-4th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 5th-6th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">2</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 7th-8th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">3</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 9th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">4</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 10th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">5</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 11th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">6</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' 12th'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">7</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' HS-grad'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">8</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Prof-school'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">9</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Assoc-acdm'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">10</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Assoc-voc'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">11</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Some-college'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">12</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Bachelors'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">13</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Masters'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">14</span><span style="color:#ABB2BF">,</span></span>
<span class="line"><span style="color:#98C379">                     ' Doctorate'</span><span style="color:#ABB2BF">: </span><span style="color:#D19A66">15</span><span style="color:#ABB2BF">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF">one_hot_ordinal </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> [</span><span style="color:#98C379">"workclass"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"race"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"occupation"</span><span style="color:#ABB2BF">, </span><span style="color:#98C379">"sex"</span><span style="color:#ABB2BF">]</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF">one_hot_data </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">get_dummies</span><span style="color:#ABB2BF">(data[one_hot_ordinal], </span><span style="color:#E06C75;font-style:italic">prefix</span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF">one_hot_ordinal)</span></span>
<span class="line"><span style="color:#ABB2BF">encoded_data_ordinal </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">concat</span><span style="color:#ABB2BF">([data, one_hot_data], </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">).</span><span style="color:#61AFEF">drop</span><span style="color:#ABB2BF">(one_hot_ordinal, </span><span style="color:#E06C75;font-style:italic">axis</span><span style="color:#56B6C2">=</span><span style="color:#D19A66">1</span><span style="color:#ABB2BF">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#C678DD">for</span><span style="color:#ABB2BF"> s </span><span style="color:#C678DD">in</span><span style="color:#ABB2BF"> scale_negative:</span></span>
<span class="line"><span style="color:#ABB2BF">    scaled_data, _ </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> stats.</span><span style="color:#61AFEF">yeojohnson</span><span style="color:#ABB2BF">(encoded_data_ordinal[s].values)</span></span>
<span class="line"><span style="color:#ABB2BF">    encoded_data_ordinal[s] </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> pd.</span><span style="color:#61AFEF">Series</span><span style="color:#ABB2BF">(scaled_data.</span><span style="color:#61AFEF">flatten</span><span style="color:#ABB2BF">())</span></span>
<span class="line"><span style="color:#ABB2BF">    </span></span>
<span class="line"><span style="color:#ABB2BF">encoded_data_ordinal[</span><span style="color:#98C379">"education"</span><span style="color:#ABB2BF">] </span><span style="color:#56B6C2">=</span><span style="color:#ABB2BF"> encoded_data_ordinal[</span><span style="color:#98C379">"education"</span><span style="color:#ABB2BF">].</span><span style="color:#61AFEF">map</span><span style="color:#ABB2BF">(mapping_encoding)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#61AFEF">evaluate_solution</span><span style="color:#ABB2BF">(encoded_data_ordinal)</span></span></code></pre>
<div style="text-align:center">
    <img src="../../assets/images/posts/fe_ml/ord_metric.webp" alt="iqred" width="300">
</div>
<p>You should note, that the examples above are used to illustrate the impact and implementation of transformations you should not apply the transformations and evaluate performance so naively. After applying the transformations in a normal setting, you should do <a href="https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/#:~:text=Feature%20selection%20is%20the%20process,the%20performance%20of%20the%20model">feature selection</a>, <a href="https://cloud.google.com/ai-platform/training/docs/hyperparameter-tuning-overview#:~:text=Hyperparameter%20tuning%20takes%20advantage%20of,maximizes%20your%20model&#x27;s%20predictive%20accuracy">hyperparameter tuning</a>, <a href="https://www.iguazio.com/glossary/classification-threshold/#:~:text=The%20most%20common%20method%20for,TN)%20at%20all%20classification%20thresholds">threshold selection</a>, <a href="https://en.wikipedia.org/wiki/Model_selection">model selection</a>, <a href="https://www.investopedia.com/terms/s/sensitivityanalysis.asp#:~:text=Sensitivity%20analysis%20is%20a%20financial,a%20certain%20range%20of%20variables.">sensitivity analysis</a> before concluding to the best model. Another note, transformations can be tricky, when you apply them in a new serve set you should not do “fit_transform” method but you should apply the “transform” method (using <a href="https://scikit-learn.org/stable/">sklearn</a> lingo here, similar methods are in other modules which conduct data transformations), a nice article illustrating the difference can be found <a href="https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe">here</a>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>In summary, data transformation plays a crucial role in optimizing model performance by addressing issues related to data representation, scaling, and distribution. Moreover, data transformation enable us to utilize categorical and textual data in our machine learning model. By utilizing appropriate data transformation techniques tailored to the specific characteristics of the dataset, we can enhance the effectiveness and reliability of our machine learning models, ultimately driving better insights and decision-making in various domains.</p> </article> <ul class="my-8 astro-rynkmgph"> <li class="inline-block my-1 underline-offset-4 astro-blwjyjpt"> <a href="/tags/machine-learning/" class="text-sm pr-2 group astro-blwjyjpt"> <svg xmlns="http://www.w3.org/2000/svg" class=" scale-75 astro-blwjyjpt"><path d="M16.018 3.815 15.232 8h-4.966l.716-3.815-1.964-.37L8.232 8H4v2h3.857l-.751 4H3v2h3.731l-.714 3.805 1.965.369L8.766 16h4.966l-.714 3.805 1.965.369.783-4.174H20v-2h-3.859l.751-4H21V8h-3.733l.716-3.815-1.965-.37zM14.106 14H9.141l.751-4h4.966l-.752 4z" class="astro-blwjyjpt"></path> </svg>
&nbsp;<span class="astro-blwjyjpt">machine-learning</span> </a> </li> <li class="inline-block my-1 underline-offset-4 astro-blwjyjpt"> <a href="/tags/data-preprocessing/" class="text-sm pr-2 group astro-blwjyjpt"> <svg xmlns="http://www.w3.org/2000/svg" class=" scale-75 astro-blwjyjpt"><path d="M16.018 3.815 15.232 8h-4.966l.716-3.815-1.964-.37L8.232 8H4v2h3.857l-.751 4H3v2h3.731l-.714 3.805 1.965.369L8.766 16h4.966l-.714 3.805 1.965.369.783-4.174H20v-2h-3.859l.751-4H21V8h-3.733l.716-3.815-1.965-.37zM14.106 14H9.141l.751-4h4.966l-.752 4z" class="astro-blwjyjpt"></path> </svg>
&nbsp;<span class="astro-blwjyjpt">data-preprocessing</span> </a> </li> <li class="inline-block my-1 underline-offset-4 astro-blwjyjpt"> <a href="/tags/python/" class="text-sm pr-2 group astro-blwjyjpt"> <svg xmlns="http://www.w3.org/2000/svg" class=" scale-75 astro-blwjyjpt"><path d="M16.018 3.815 15.232 8h-4.966l.716-3.815-1.964-.37L8.232 8H4v2h3.857l-.751 4H3v2h3.731l-.714 3.805 1.965.369L8.766 16h4.966l-.714 3.805 1.965.369.783-4.174H20v-2h-3.859l.751-4H21V8h-3.733l.716-3.815-1.965-.37zM14.106 14H9.141l.751-4h4.966l-.752 4z" class="astro-blwjyjpt"></path> </svg>
&nbsp;<span class="astro-blwjyjpt">python</span> </a> </li>  </ul> <div class="flex flex-col-reverse items-center justify-between gap-6 sm:flex-row-reverse sm:items-end sm:gap-4 astro-rynkmgph"> <button id="back-to-top" class="focus-outline whitespace-nowrap py-1 hover:opacity-75 astro-rynkmgph"> <svg xmlns="http://www.w3.org/2000/svg" class="rotate-90 astro-rynkmgph"> <path d="M13.293 6.293 7.586 12l5.707 5.707 1.414-1.414L10.414 12l4.293-4.293z" class="astro-rynkmgph"></path> </svg> <span class="astro-rynkmgph">Back to Top</span> </button> </div> </main> <footer class="mt-auto astro-sz7xmlte"> <div class="mx-auto px-0"> <hr class="border-skin-line" aria-hidden="true"> </div> <div class="footer-wrapper astro-sz7xmlte"> <div class="social-icons flex astro-upu6fzxr"> <a href="https://buy.stripe.com/28obMAdue2or07udQR" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Support Vasileios Tsakalos via Stripe (monthly subscription)" title="Support Vasileios Tsakalos via Stripe (monthly subscription)" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M11.453 8.056c0 -.623 .518 -.979 1.442 -.979c1.69 0 3.41 .343 4.605 .923l.5 -4c-.948 -.449 -2.82 -1 -5.5 -1c-1.895 0 -3.373 .087 -4.5 1c-1.172 .956 -2 2.33 -2 4c0 3.03 1.958 4.906 5 6c1.961 .69 3 .743 3 1.5c0 .735 -.851 1.5 -2 1.5c-1.423 0 -3.963 -.609 -5.5 -1.5l-.5 4c1.321 .734 3.474 1.5 6 1.5c2 0 3.957 -.468 5.084 -1.36c1.263 -.979 1.916 -2.268 1.916 -4.14c0 -3.096 -1.915 -4.547 -5 -5.637c-1.646 -.605 -2.544 -1.07 -2.544 -1.807z" /></svg> <span class="sr-only astro-upu6fzxr">Support Vasileios Tsakalos via Stripe (monthly subscription)</span> </a><a href="https://donate.stripe.com/9AQcQE61M6EHcUg9AA" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Support Vasileios Tsakalos via Stripe (one-time donation)" title="Support Vasileios Tsakalos via Stripe (one-time donation)" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0" /><path d="M14.8 9a2 2 0 0 0 -1.8 -1h-2a2 2 0 1 0 0 4h2a2 2 0 1 1 0 4h-2a2 2 0 0 1 -1.8 -1" /><path d="M12 7v10" /></svg> <span class="sr-only astro-upu6fzxr">Support Vasileios Tsakalos via Stripe (one-time donation)</span> </a><a href="https://paypal.me/gpiskas" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Support Vasileios Tsakalos via PayPal (one-time donation)" title="Support Vasileios Tsakalos via PayPal (one-time donation)" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M10 13l2.5 0c2.5 0 5 -2.5 5 -5c0 -3 -1.9 -5 -5 -5h-5.5c-.5 0 -1 .5 -1 1l-2 14c0 .5 .5 1 1 1h2.8l1.2 -5c.1 -.6 .4 -1 1 -1zm7.5 -5.8c1.7 1 2.5 2.8 2.5 4.8c0 2.5 -2.5 4.5 -5 4.5h-2.6l-.6 3.6a1 1 0 0 1 -1 .8l-2.7 0a.5 .5 0 0 1 -.5 -.6l.2 -1.4" /></svg> <span class="sr-only astro-upu6fzxr">Support Vasileios Tsakalos via PayPal (one-time donation)</span> </a><a href="https://ko-fi.com/gpiskas" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Support Vasileios Tsakalos via Ko-Fi" title="Support Vasileios Tsakalos via Ko-Fi" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 14c.83 .642 2.077 1.017 3.5 1c1.423 .017 2.67 -.358 3.5 -1c.83 -.642 2.077 -1.017 3.5 -1c1.423 -.017 2.67 .358 3.5 1" /><path d="M8 3a2.4 2.4 0 0 0 -1 2a2.4 2.4 0 0 0 1 2" /><path d="M12 3a2.4 2.4 0 0 0 -1 2a2.4 2.4 0 0 0 1 2" /><path d="M3 10h14v5a6 6 0 0 1 -6 6h-2a6 6 0 0 1 -6 -6v-5z" /><path d="M16.746 16.726a3 3 0 1 0 .252 -5.555" /></svg> <span class="sr-only astro-upu6fzxr">Support Vasileios Tsakalos via Ko-Fi</span> </a><a href="https://www.linkedin.com/in/vasileiostsakalos" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Vasileios Tsakalos on LinkedIn" title="Vasileios Tsakalos on LinkedIn" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v12a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2z" /><path d="M8 11l0 5" /><path d="M8 8l0 .01" /><path d="M12 16l0 -5" /><path d="M16 16v-3a2 2 0 0 0 -4 0" /></svg> <span class="sr-only astro-upu6fzxr">Vasileios Tsakalos on LinkedIn</span> </a><a href="https://github.com/sponsors/VasTsak" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Vasileios Tsakalos on GitHub" title="Vasileios Tsakalos on GitHub" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" /></svg> <span class="sr-only astro-upu6fzxr">Vasileios Tsakalos on GitHub</span> </a><a href="mailto:vtsakalos@proton.me" class="group hover:text-skin-accent link-button astro-upu6fzxr" aria-label="Send an email to Vasileios Tsakalos" title="Send an email to Vasileios Tsakalos" target="_blank"> <svg xmlns="http://www.w3.org/2000/svg" class="icon-tabler" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M13 19h-8a2 2 0 0 1 -2 -2v-10a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v6" /><path d="M3 7l9 6l9 -6" /><path d="M16 22l5 -5" /><path d="M21 21.5v-4.5h-4.5" /></svg> <span class="sr-only astro-upu6fzxr">Send an email to Vasileios Tsakalos</span> </a> </div>  <div class="copyright-wrapper astro-sz7xmlte"> <span class="astro-sz7xmlte">Vasileios Tsakalos &#169; 2024</span> <span class="separator astro-sz7xmlte">&nbsp;|&nbsp;</span> <span class="highlight astro-sz7xmlte">Imagine anything, can create the impossible.</span> </div> </div> </footer>   </body></html>  <script>
  /** Attaches links to headings in the document,
   *  allowing sharing of sections easily */
  function addHeadingLinks() {
    let headings = Array.from(document.querySelectorAll("h2, h3, h4, h5, h6"));
    for (let heading of headings) {
      heading.classList.add("group");
      let link = document.createElement("a");
      link.innerText = "#";
      link.className = "heading-link hidden group-hover:inline-block ml-2";
      link.href = "#" + heading.id;
      link.ariaHidden = "true";
      heading.appendChild(link);
    }
  }
  addHeadingLinks();

  /** Attaches copy buttons to code blocks in the document,
   * allowing users to copy code easily. */
  function attachCopyButtons() {
    let copyButtonLabel = "Copy";
    let codeBlocks = Array.from(document.querySelectorAll("pre"));

    for (let codeBlock of codeBlocks) {
      let wrapper = document.createElement("div");
      wrapper.style.position = "relative";

      let copyButton = document.createElement("button");
      copyButton.className =
        "copy-code absolute right-3 -top-3 rounded bg-skin-card px-2 py-1 text-xs leading-4 text-skin-base font-medium";
      copyButton.innerHTML = copyButtonLabel;
      codeBlock.setAttribute("tabindex", "0");
      codeBlock.appendChild(copyButton);

      // wrap codebock with relative parent element
      codeBlock?.parentNode?.insertBefore(wrapper, codeBlock);
      wrapper.appendChild(codeBlock);

      copyButton.addEventListener("click", async () => {
        await copyCode(codeBlock, copyButton);
      });
    }

    async function copyCode(block, button) {
      let code = block.querySelector("code");
      let text = code?.innerText;

      await navigator.clipboard.writeText(text ?? "");

      // visual feedback that task is completed
      button.innerText = "Copied";

      setTimeout(() => {
        button.innerText = copyButtonLabel;
      }, 700);
    }
  }
  attachCopyButtons();

  /** Scrolls the document to the top when
   * the "Back to Top" button is clicked. */
  function backToTop() {
    document.querySelector("#back-to-top")?.addEventListener("click", () => {
      document.body.scrollTop = 0; // For Safari
      document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
    });
  }
  backToTop();
</script>